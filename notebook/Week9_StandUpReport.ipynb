{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec2e1694-1344-4260-851c-ee6fcdf8cb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\programdata\\miniconda\\lib\\site-packages (1.39.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (5.4.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (4.25.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (18.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (13.9.2)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog<6,>=2.1.5 in c:\\programdata\\miniconda\\lib\\site-packages (from streamlit) (5.0.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\miniconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\programdata\\miniconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in c:\\programdata\\miniconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.12.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\programdata\\miniconda\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\miniconda\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\miniconda\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\miniconda\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\miniconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\miniconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\miniconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\miniconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\miniconda\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\miniconda\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\programdata\\miniconda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\miniconda\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\programdata\\miniconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\miniconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\miniconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\miniconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\miniconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\miniconda\\lib\\site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\miniconda\\lib\\site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\miniconda\\lib\\site-packages (from plotly) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "022b147f-74fc-498c-9e2e-9b448a703303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43474e18-2653-4391-bcea-352ba6c5edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file path\n",
    "DATA_PATH = \"C:/Intro_DataScience/Week4/Academic_Success_Data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eb6f822-82ea-4206-b3b6-548c4715c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentDropoutPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier(random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load the dataset.\"\"\"\n",
    "        try:\n",
    "            # Load data\n",
    "            df = pd.read_csv(DATA_PATH)\n",
    "            print(\"Data loaded successfully!\")\n",
    "            print(\"Shape of data:\", df.shape)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Preprocess the data.\"\"\"\n",
    "        # Filter for only Dropout and Graduate\n",
    "        df = df[df['Target'].isin(['Dropout', 'Graduate'])]\n",
    "        \n",
    "        # Feature engineering\n",
    "        df['first_sem_success_ratio'] = df['Curricular units 1st sem (approved)'] / df['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "        df['second_sem_success_ratio'] = df['Curricular units 2nd sem (approved)'] / df['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "        df['average_grade'] = (df['Curricular units 1st sem (grade)'] + df['Curricular units 2nd sem (grade)']) / 2\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Prepare features for modeling.\"\"\"\n",
    "        # Select features\n",
    "        features = [\n",
    "            'Age at enrollment', 'Previous qualification (grade)', 'Admission grade',\n",
    "            'Curricular units 1st sem (enrolled)', 'Curricular units 2nd sem (enrolled)',\n",
    "            'first_sem_success_ratio', 'second_sem_success_ratio', 'average_grade'\n",
    "        ]\n",
    "        \n",
    "        X = df[features]\n",
    "        y = df['Target']\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test, features\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        self.model.fit(X_train, y_train)\n",
    "        print(\"Model trained successfully!\")\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"Evaluate the model.\"\"\"\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        # Scale the input data\n",
    "        input_scaled = self.scaler.transform(input_data)\n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(input_scaled)\n",
    "        probability = self.model.predict_proba(input_scaled)\n",
    "        return prediction[0], probability[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "374f7381-f613-4f4b-9b0e-34c1b67fb4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StudentDropoutPredictor' object has no attribute 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(probability)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[52], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Preprocess data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPreprocessing data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StudentDropoutPredictor' object has no attribute 'load_data'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Create predictor instance\n",
    "    predictor = StudentDropoutPredictor()\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = predictor.load_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Preprocess data\n",
    "        print(\"\\nPreprocessing data...\")\n",
    "        df_processed = predictor.preprocess_data(df)\n",
    "        \n",
    "        # Prepare features\n",
    "        print(\"\\nPreparing features...\")\n",
    "        X_train, X_test, y_train, y_test, features = predictor.prepare_features(df_processed)\n",
    "        \n",
    "        # Train model\n",
    "        print(\"\\nTraining model...\")\n",
    "        predictor.train_model(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"\\nEvaluating model...\")\n",
    "        predictor.evaluate_model(X_test, y_test)\n",
    "        \n",
    "        # Example prediction\n",
    "        print(\"\\nMaking example prediction...\")\n",
    "        example_data = pd.DataFrame({\n",
    "            'Age at enrollment': [20],\n",
    "            'Previous qualification (grade)': [120],\n",
    "            'Admission grade': [130],\n",
    "            'Curricular units 1st sem (enrolled)': [6],\n",
    "            'Curricular units 2nd sem (enrolled)': [6],\n",
    "            'first_sem_success_ratio': [0.8],\n",
    "            'second_sem_success_ratio': [0.8],\n",
    "            'average_grade': [12.5]\n",
    "        })\n",
    "        \n",
    "        prediction, probability = predictor.predict(example_data)\n",
    "        print(f\"\\nPredicted outcome: {prediction}\")\n",
    "        print(f\"Probability: {max(probability):.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca3fc3-353f-4ac1-b48f-e89d7ac6c9fe",
   "metadata": {},
   "source": [
    "Alternate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c69ccd09-0675-4a33-9a4b-d63d2aa18bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2ba5c09-d0b5-4ea9-9dae-6fe0fcb52fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentDropoutPredictor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the predictor with model and scaler.\"\"\"\n",
    "        self.model = RandomForestClassifier(random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.features = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load the dataset.\"\"\"\n",
    "        try:\n",
    "            # Load data with explicit encoding\n",
    "            df = pd.read_csv(\"C:/Intro_DataScience/Week4/Academic_Success_Data.csv\", encoding='utf-8')\n",
    "            print(\"Data loaded successfully!\")\n",
    "            print(\"Shape of data:\", df.shape)\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: File not found. Please check the file path.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Preprocess the data.\"\"\"\n",
    "        try:\n",
    "            # Filter for only Dropout and Graduate\n",
    "            df = df[df['Target'].isin(['Dropout', 'Graduate'])]\n",
    "            \n",
    "            # Feature engineering\n",
    "            df['first_sem_success_ratio'] = (\n",
    "                df['Curricular units 1st sem (approved)'] / \n",
    "                df['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "            )\n",
    "            \n",
    "            df['second_sem_success_ratio'] = (\n",
    "                df['Curricular units 2nd sem (approved)'] / \n",
    "                df['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "            )\n",
    "            \n",
    "            df['average_grade'] = (\n",
    "                df['Curricular units 1st sem (grade)'] + \n",
    "                df['Curricular units 2nd sem (grade)']\n",
    "            ) / 2\n",
    "            \n",
    "            print(\"Data preprocessing completed successfully!\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in preprocessing: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Prepare features for modeling.\"\"\"\n",
    "        try:\n",
    "            # Select features\n",
    "            self.features = [\n",
    "                'Age at enrollment',\n",
    "                'Previous qualification (grade)',\n",
    "                'Admission grade',\n",
    "                'Curricular units 1st sem (enrolled)',\n",
    "                'Curricular units 2nd sem (enrolled)',\n",
    "                'first_sem_success_ratio',\n",
    "                'second_sem_success_ratio',\n",
    "                'average_grade'\n",
    "            ]\n",
    "            \n",
    "            X = df[self.features]\n",
    "            y = df['Target']\n",
    "            \n",
    "            # Split the data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "            \n",
    "            print(\"Features prepared successfully!\")\n",
    "            return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in feature preparation: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        try:\n",
    "            self.model.fit(X_train, y_train)\n",
    "            print(\"Model trained successfully!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error in model training: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"Evaluate the model.\"\"\"\n",
    "        try:\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error in model evaluation: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        try:\n",
    "            # Ensure input data has all required features\n",
    "            for feature in self.features:\n",
    "                if feature not in input_data.columns:\n",
    "                    raise ValueError(f\"Missing feature: {feature}\")\n",
    "            \n",
    "            # Scale the input data\n",
    "            input_scaled = self.scaler.transform(input_data)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = self.model.predict(input_scaled)\n",
    "            probability = self.model.predict_proba(input_scaled)\n",
    "            \n",
    "            return prediction[0], probability[0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in prediction: {str(e)}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71afb454-35bf-44bd-904f-4a6fc92b5ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully!\n",
      "Shape of data: (4424, 37)\n",
      "\n",
      "Preprocessing data...\n",
      "Data preprocessing completed successfully!\n",
      "\n",
      "Preparing features...\n",
      "Features prepared successfully!\n",
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashir\\AppData\\Local\\Temp\\ipykernel_51276\\335837934.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['first_sem_success_ratio'] = (\n",
      "C:\\Users\\ashir\\AppData\\Local\\Temp\\ipykernel_51276\\335837934.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['second_sem_success_ratio'] = (\n",
      "C:\\Users\\ashir\\AppData\\Local\\Temp\\ipykernel_51276\\335837934.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['average_grade'] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.87      0.83      0.85       277\n",
      "    Graduate       0.90      0.93      0.91       449\n",
      "\n",
      "    accuracy                           0.89       726\n",
      "   macro avg       0.89      0.88      0.88       726\n",
      "weighted avg       0.89      0.89      0.89       726\n",
      "\n",
      "\n",
      "Making example prediction...\n",
      "\n",
      "Predicted outcome: Graduate\n",
      "Probability: 71.00%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Create predictor instance\n",
    "    predictor = StudentDropoutPredictor()\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = predictor.load_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Preprocess data\n",
    "        print(\"\\nPreprocessing data...\")\n",
    "        df_processed = predictor.preprocess_data(df)\n",
    "        \n",
    "        if df_processed is not None:\n",
    "            # Prepare features\n",
    "            print(\"\\nPreparing features...\")\n",
    "            result = predictor.prepare_features(df_processed)\n",
    "            \n",
    "            if result is not None:\n",
    "                X_train, X_test, y_train, y_test = result\n",
    "                \n",
    "                # Train model\n",
    "                print(\"\\nTraining model...\")\n",
    "                if predictor.train_model(X_train, y_train):\n",
    "                    \n",
    "                    # Evaluate model\n",
    "                    print(\"\\nEvaluating model...\")\n",
    "                    predictor.evaluate_model(X_test, y_test)\n",
    "                    \n",
    "                    # Example prediction\n",
    "                    print(\"\\nMaking example prediction...\")\n",
    "                    example_data = pd.DataFrame({\n",
    "                        'Age at enrollment': [20],\n",
    "                        'Previous qualification (grade)': [120],\n",
    "                        'Admission grade': [130],\n",
    "                        'Curricular units 1st sem (enrolled)': [6],\n",
    "                        'Curricular units 2nd sem (enrolled)': [6],\n",
    "                        'first_sem_success_ratio': [0.8],\n",
    "                        'second_sem_success_ratio': [0.8],\n",
    "                        'average_grade': [12.5]\n",
    "                    })\n",
    "                    \n",
    "                    prediction, probability = predictor.predict(example_data)\n",
    "                    if prediction is not None:\n",
    "                        print(f\"\\nPredicted outcome: {prediction}\")\n",
    "                        print(f\"Probability: {max(probability):.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b801d0c-a560-40e8-8d32-5fd5df1a737e",
   "metadata": {},
   "source": [
    "## Enhancing the model and adding in new Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f541a3ba-aadb-43da-9298-c070c691aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6802f0be-628c-4d98-8dbd-85faa6631659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentDropoutPredictor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the predictor with model and scaler.\"\"\"\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.features = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load the dataset.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(\"C:/Intro_DataScience/Week4/Academic_Success_Data.csv\", encoding='utf-8')\n",
    "            print(\"Data loaded successfully!\")\n",
    "            print(\"Shape of data:\", df.shape)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Preprocess the data.\"\"\"\n",
    "        try:\n",
    "            # Create a copy to avoid SettingWithCopyWarning\n",
    "            df_processed = df.copy()\n",
    "            \n",
    "            # Filter for only Dropout and Graduate\n",
    "            mask = df_processed['Target'].isin(['Dropout', 'Graduate'])\n",
    "            df_processed = df_processed[mask].copy()\n",
    "            \n",
    "            # Feature engineering\n",
    "            df_processed.loc[:, 'first_sem_success_ratio'] = (\n",
    "                df_processed['Curricular units 1st sem (approved)'] / \n",
    "                df_processed['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "            )\n",
    "            \n",
    "            df_processed.loc[:, 'second_sem_success_ratio'] = (\n",
    "                df_processed['Curricular units 2nd sem (approved)'] / \n",
    "                df_processed['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "            )\n",
    "            \n",
    "            df_processed.loc[:, 'average_grade'] = (\n",
    "                df_processed['Curricular units 1st sem (grade)'] + \n",
    "                df_processed['Curricular units 2nd sem (grade)']\n",
    "            ) / 2\n",
    "            \n",
    "            # Additional feature engineering\n",
    "            df_processed.loc[:, 'performance_change'] = (\n",
    "                df_processed['Curricular units 2nd sem (grade)'] - \n",
    "                df_processed['Curricular units 1st sem (grade)']\n",
    "            )\n",
    "            \n",
    "            df_processed.loc[:, 'economic_factor'] = (\n",
    "                df_processed['Unemployment rate'] * \n",
    "                (1 - df_processed['Scholarship holder']) * \n",
    "                (1 - df_processed['Tuition fees up to date'])\n",
    "            )\n",
    "            \n",
    "            print(\"Data preprocessing completed successfully!\")\n",
    "            return df_processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in preprocessing: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Prepare features for modeling.\"\"\"\n",
    "        try:\n",
    "            # Select features\n",
    "            self.features = [\n",
    "                'Age at enrollment',\n",
    "                'Previous qualification (grade)',\n",
    "                'Admission grade',\n",
    "                'Curricular units 1st sem (enrolled)',\n",
    "                'Curricular units 2nd sem (enrolled)',\n",
    "                'first_sem_success_ratio',\n",
    "                'second_sem_success_ratio',\n",
    "                'average_grade',\n",
    "                'performance_change',\n",
    "                'economic_factor',\n",
    "                'Scholarship holder',\n",
    "                'Tuition fees up to date',\n",
    "                'International',\n",
    "                'Displacement'\n",
    "            ]\n",
    "            \n",
    "            X = df[self.features]\n",
    "            y = df['Target']\n",
    "            \n",
    "            # Split the data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "            \n",
    "            print(\"Features prepared successfully!\")\n",
    "            return X_train_scaled, X_test_scaled, y_train, y_test, X.columns\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in feature preparation: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def train_model(self, X_train, y_train):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        try:\n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            # Perform cross-validation\n",
    "            cv_scores = cross_val_score(self.model, X_train, y_train, cv=5)\n",
    "            print(\"\\nCross-validation scores:\", cv_scores)\n",
    "            print(f\"Average CV score: {cv_scores.mean():.2f} (+/- {cv_scores.std() * 2:.2f})\")\n",
    "            \n",
    "            # Get feature importance\n",
    "            self.plot_feature_importance()\n",
    "            \n",
    "            print(\"Model trained successfully!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error in model training: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def plot_feature_importance(self):\n",
    "        \"\"\"Plot feature importance.\"\"\"\n",
    "        try:\n",
    "            importance = pd.DataFrame({\n",
    "                'feature': self.features,\n",
    "                'importance': self.model.feature_importances_\n",
    "            })\n",
    "            importance = importance.sort_values('importance', ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(data=importance, x='importance', y='feature')\n",
    "            plt.title('Feature Importance')\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting feature importance: {str(e)}\")\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        \"\"\"Evaluate the model.\"\"\"\n",
    "        try:\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            y_prob = self.model.predict_proba(X_test)\n",
    "            \n",
    "            # Print classification report\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Plot confusion matrix\n",
    "            self.plot_confusion_matrix(y_test, y_pred)\n",
    "            \n",
    "            # Plot ROC curve\n",
    "            self.plot_roc_curve(y_test, y_prob[:, 1])\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error in model evaluation: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"Plot confusion matrix.\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_roc_curve(self, y_true, y_prob):\n",
    "        \"\"\"Plot ROC curve.\"\"\"\n",
    "        fpr, tpr, _ = roc_curve(y_true == 'Graduate', y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        \"\"\"Make predictions.\"\"\"\n",
    "        try:\n",
    "            # Scale the input data\n",
    "            input_scaled = self.scaler.transform(input_data)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = self.model.predict(input_scaled)\n",
    "            probability = self.model.predict_proba(input_scaled)\n",
    "            \n",
    "            return prediction[0], probability[0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in prediction: {str(e)}\")\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d81e5cd-d304-4bab-be69-df4d4a6cd24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully!\n",
      "Shape of data: (4424, 37)\n",
      "\n",
      "Preprocessing data...\n",
      "Data preprocessing completed successfully!\n",
      "\n",
      "Preparing features...\n",
      "Error in feature preparation: \"['Displacement'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Create predictor instance\n",
    "    predictor = StudentDropoutPredictor()\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    df = predictor.load_data()\n",
    "    \n",
    "    if df is not None:\n",
    "        # Preprocess data\n",
    "        print(\"\\nPreprocessing data...\")\n",
    "        df_processed = predictor.preprocess_data(df)\n",
    "        \n",
    "        if df_processed is not None:\n",
    "            # Prepare features\n",
    "            print(\"\\nPreparing features...\")\n",
    "            result = predictor.prepare_features(df_processed)\n",
    "            \n",
    "            if result is not None:\n",
    "                X_train, X_test, y_train, y_test, feature_names = result\n",
    "                \n",
    "                # Train model\n",
    "                print(\"\\nTraining model...\")\n",
    "                if predictor.train_model(X_train, y_train):\n",
    "                    \n",
    "                    # Evaluate model\n",
    "                    print(\"\\nEvaluating model...\")\n",
    "                    predictor.evaluate_model(X_test, y_test)\n",
    "                    \n",
    "                    # Example prediction\n",
    "                    print(\"\\nMaking example prediction...\")\n",
    "                    example_data = pd.DataFrame({\n",
    "                        'Age at enrollment': [20],\n",
    "                        'Previous qualification (grade)': [120],\n",
    "                        'Admission grade': [130],\n",
    "                        'Curricular units 1st sem (enrolled)': [6],\n",
    "                        'Curricular units 2nd sem (enrolled)': [6],\n",
    "                        'first_sem_success_ratio': [0.8],\n",
    "                        'second_sem_success_ratio': [0.8],\n",
    "                        'average_grade': [12.5],\n",
    "                        'performance_change': [0.5],\n",
    "                        'economic_factor': [5.0],\n",
    "                        'Scholarship holder': [1],\n",
    "                        'Tuition fees up to date': [1],\n",
    "                        'International': [0],\n",
    "                        'Displacement': [0]\n",
    "                    })\n",
    "                    \n",
    "                    prediction, probability = predictor.predict(example_data)\n",
    "                    if prediction is not None:\n",
    "                        print(f\"\\nPredicted outcome: {prediction}\")\n",
    "                        print(f\"Probability: {max(probability):.2%}\")\n",
    "                        \n",
    "                    # Save the model\n",
    "                    dump(predictor, 'student_dropout_predictor.joblib')\n",
    "                    print(\"\\nModel saved successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296fc37-a8e5-4a2e-8b10-e68cb92d5a22",
   "metadata": {},
   "source": [
    "## Alternate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c50dc022-e9e4-4d83-afaa-c944f5e5124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, mutual_info_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da03ed59-aece-46f5-b650-f3ca558d2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize feature selector with various methods.\"\"\"\n",
    "        self.selected_features = None\n",
    "        self.feature_importance = None\n",
    "        self.correlation_matrix = None\n",
    "    \n",
    "    def correlation_analysis(self, df, threshold=0.8):\n",
    "        \"\"\"Remove highly correlated features.\"\"\"\n",
    "        # Calculate correlation matrix\n",
    "        correlation_matrix = df.corr()\n",
    "        self.correlation_matrix = correlation_matrix\n",
    "        \n",
    "        # Plot correlation heatmap\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Feature Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Find highly correlated features\n",
    "        high_corr_features = []\n",
    "        for i in range(len(correlation_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "                    colname = correlation_matrix.columns[i]\n",
    "                    high_corr_features.append(colname)\n",
    "        \n",
    "        return list(set(high_corr_features))\n",
    "    \n",
    "    def mutual_information(self, X, y, n_features=10):\n",
    "        \"\"\"Select features based on mutual information.\"\"\"\n",
    "        mi_scores = mutual_info_classif(X, y)\n",
    "        mi_scores = pd.Series(mi_scores, index=X.columns)\n",
    "        mi_scores = mi_scores.sort_values(ascending=False)\n",
    "        \n",
    "        # Plot mutual information scores\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        mi_scores.plot(kind='bar')\n",
    "        plt.title('Mutual Information Scores')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Mutual Information')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return mi_scores.head(n_features).index.tolist()\n",
    "    \n",
    "    def recursive_feature_elimination(self, X, y, n_features=10):\n",
    "        \"\"\"Perform recursive feature elimination.\"\"\"\n",
    "        estimator = RandomForestClassifier(random_state=42)\n",
    "        selector = RFE(estimator=estimator, n_features_to_select=n_features)\n",
    "        selector = selector.fit(X, y)\n",
    "        \n",
    "        # Get selected features\n",
    "        selected_features = X.columns[selector.support_].tolist()\n",
    "        \n",
    "        # Plot RFE rankings\n",
    "        rankings = pd.Series(selector.ranking_, index=X.columns)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        rankings.plot(kind='bar')\n",
    "        plt.title('RFE Feature Rankings')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Ranking (1 = Selected)')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return selected_features\n",
    "    \n",
    "    def select_features(self, X, y, correlation_threshold=0.8, n_features=10):\n",
    "        \"\"\"Combine multiple feature selection methods.\"\"\"\n",
    "        print(\"\\nPerforming feature selection...\")\n",
    "        \n",
    "        # 1. Remove highly correlated features\n",
    "        print(\"\\n1. Correlation Analysis:\")\n",
    "        high_corr_features = self.correlation_analysis(X, correlation_threshold)\n",
    "        print(f\"Highly correlated features to remove: {high_corr_features}\")\n",
    "        \n",
    "        # 2. Mutual Information\n",
    "        print(\"\\n2. Mutual Information Analysis:\")\n",
    "        mi_features = self.mutual_information(X, y, n_features)\n",
    "        print(f\"Top features by mutual information: {mi_features}\")\n",
    "        \n",
    "        # 3. Recursive Feature Elimination\n",
    "        print(\"\\n3. Recursive Feature Elimination:\")\n",
    "        rfe_features = self.recursive_feature_elimination(X, y, n_features)\n",
    "        print(f\"Features selected by RFE: {rfe_features}\")\n",
    "        \n",
    "        # Combine results (features that appear in at least 2 methods)\n",
    "        all_features = set(X.columns) - set(high_corr_features)\n",
    "        selected_features = [f for f in all_features if sum([\n",
    "            f in mi_features,\n",
    "            f in rfe_features\n",
    "        ]) >= 1]\n",
    "        \n",
    "        self.selected_features = selected_features\n",
    "        print(f\"\\nFinal selected features: {selected_features}\")\n",
    "        return selected_features\n",
    "\n",
    "class StudentDropoutPredictor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the predictor.\"\"\"\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_selector = FeatureSelector()\n",
    "        self.features = None\n",
    "    \n",
    "    def load_and_preprocess_data(self, data_path):\n",
    "        \"\"\"Load and preprocess the data.\"\"\"\n",
    "        try:\n",
    "            # Load data\n",
    "            df = pd.read_csv(data_path, encoding='utf-8')\n",
    "            print(\"Data loaded successfully!\")\n",
    "            print(\"Shape of data:\", df.shape)\n",
    "            \n",
    "            # Create a copy to avoid warnings\n",
    "            df_processed = df.copy()\n",
    "            \n",
    "            # Filter for only Dropout and Graduate\n",
    "            mask = df_processed['Target'].isin(['Dropout', 'Graduate'])\n",
    "            df_processed = df_processed[mask].copy()\n",
    "            \n",
    "            # Feature engineering\n",
    "            df_processed.loc[:, 'first_sem_success_ratio'] = (\n",
    "                df_processed['Curricular units 1st sem (approved)'] / \n",
    "                df_processed['Curricular units 1st sem (enrolled)'].replace(0, 1)\n",
    "            )\n",
    "            \n",
    "            df_processed.loc[:, 'second_sem_success_ratio'] = (\n",
    "                df_processed['Curricular units 2nd sem (approved)'] / \n",
    "                df_processed['Curricular units 2nd sem (enrolled)'].replace(0, 1)\n",
    "            )\n",
    "            \n",
    "            df_processed.loc[:, 'average_grade'] = (\n",
    "                df_processed['Curricular units 1st sem (grade)'] + \n",
    "                df_processed['Curricular units 2nd sem (grade)']\n",
    "            ) / 2\n",
    "            \n",
    "            df_processed.loc[:, 'performance_change'] = (\n",
    "                df_processed['Curricular units 2nd sem (grade)'] - \n",
    "                df_processed['Curricular units 1st sem (grade)']\n",
    "            )\n",
    "            \n",
    "            df_processed.loc[:, 'economic_factor'] = (\n",
    "                df_processed['Unemployment rate'] * \n",
    "                (1 - df_processed['Scholarship holder']) * \n",
    "                (1 - df_processed['Tuition fees up to date'])\n",
    "            )\n",
    "            \n",
    "            return df_processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in data processing: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"Prepare features for modeling with feature selection.\"\"\"\n",
    "        try:\n",
    "            # Initial feature set\n",
    "            initial_features = [\n",
    "                'Age at enrollment',\n",
    "                'Previous qualification (grade)',\n",
    "                'Admission grade',\n",
    "                'Curricular units 1st sem (enrolled)',\n",
    "                'Curricular units 2nd sem (enrolled)',\n",
    "                'first_sem_success_ratio',\n",
    "                'second_sem_success_ratio',\n",
    "                'average_grade',\n",
    "                'performance_change',\n",
    "                'economic_factor',\n",
    "                'Scholarship holder',\n",
    "                'Tuition fees up to date',\n",
    "                'International'\n",
    "            ]\n",
    "            \n",
    "            X = df[initial_features]\n",
    "            y = df['Target']\n",
    "            \n",
    "            # Perform feature selection\n",
    "            selected_features = self.feature_selector.select_features(X, y)\n",
    "            self.features = selected_features\n",
    "            \n",
    "            # Use selected features\n",
    "            X = df[selected_features]\n",
    "            \n",
    "            # Split and scale data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "            \n",
    "            return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in feature preparation: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def train_and_evaluate(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train and evaluate the model.\"\"\"\n",
    "        try:\n",
    "            # Train model\n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            train_score = self.model.score(X_train, y_train)\n",
    "            test_score = self.model.score(X_test, y_test)\n",
    "            \n",
    "            print(\"\\nModel Performance:\")\n",
    "            print(f\"Training accuracy: {train_score:.4f}\")\n",
    "            print(f\"Testing accuracy: {test_score:.4f}\")\n",
    "            \n",
    "            # Classification report\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error in training/evaluation: {str(e)}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "01845f49-4847-471d-b763-9ef99ac6cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Data loaded successfully!\n",
      "Shape of data: (4424, 37)\n",
      "\n",
      "Preparing features...\n",
      "\n",
      "Performing feature selection...\n",
      "\n",
      "1. Correlation Analysis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashir\\AppData\\Local\\Temp\\ipykernel_51276\\64319246.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated features to remove: ['Tuition fees up to date', 'average_grade', 'Curricular units 2nd sem (enrolled)', 'second_sem_success_ratio']\n",
      "\n",
      "2. Mutual Information Analysis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashir\\AppData\\Local\\Temp\\ipykernel_51276\\64319246.py:45: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features by mutual information: ['second_sem_success_ratio', 'first_sem_success_ratio', 'average_grade', 'performance_change', 'Tuition fees up to date', 'economic_factor', 'Age at enrollment', 'Scholarship holder', 'Curricular units 1st sem (enrolled)', 'Curricular units 2nd sem (enrolled)']\n",
      "\n",
      "3. Recursive Feature Elimination:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashir\\AppData\\Local\\Temp\\ipykernel_51276\\64319246.py:67: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by RFE: ['Age at enrollment', 'Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (enrolled)', 'first_sem_success_ratio', 'second_sem_success_ratio', 'average_grade', 'performance_change', 'economic_factor', 'Tuition fees up to date']\n",
      "\n",
      "Final selected features: ['Previous qualification (grade)', 'Age at enrollment', 'Scholarship holder', 'first_sem_success_ratio', 'Curricular units 1st sem (enrolled)', 'economic_factor', 'performance_change', 'Admission grade']\n",
      "\n",
      "Training and evaluating model...\n",
      "\n",
      "Model Performance:\n",
      "Training accuracy: 0.9273\n",
      "Testing accuracy: 0.8912\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.92      0.79      0.85       284\n",
      "    Graduate       0.88      0.96      0.91       442\n",
      "\n",
      "    accuracy                           0.89       726\n",
      "   macro avg       0.90      0.87      0.88       726\n",
      "weighted avg       0.89      0.89      0.89       726\n",
      "\n",
      "\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize predictor\n",
    "    predictor = StudentDropoutPredictor()\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    df = predictor.load_and_preprocess_data(\"C:/Intro_DataScience/Week4/Academic_Success_Data.csv\")\n",
    "    \n",
    "    if df is not None:\n",
    "        # Prepare features with selection\n",
    "        print(\"\\nPreparing features...\")\n",
    "        result = predictor.prepare_features(df)\n",
    "        \n",
    "        if result is not None:\n",
    "            X_train, X_test, y_train, y_test = result\n",
    "            \n",
    "            # Train and evaluate model\n",
    "            print(\"\\nTraining and evaluating model...\")\n",
    "            predictor.train_and_evaluate(X_train, y_train, X_test, y_test)\n",
    "            \n",
    "            # Save the model\n",
    "            dump(predictor, 'student_dropout_predictor.joblib')\n",
    "            print(\"\\nModel saved successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b6736-ccea-43b6-90c4-8c7059c8a598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
